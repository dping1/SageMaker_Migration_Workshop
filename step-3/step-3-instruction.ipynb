{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Model hosting using custom container\n",
    "\n",
    "In this step, we will host your model behind a SageMaker endpoint.  Depending on format of the model, you could build your own container to host the model or host the model using built-in container such as the SageMaker TensorFlow container.  First, let's create a working folder called **MY_PROJECT** and copy over some boiler plate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "DIRECTORY=MY_PROJECT\n",
    "\n",
    "target_dir=$DIRECTORY\n",
    "if [ ! -d \"$target_dir\" ]; then\n",
    "    mkdir $target_dir\n",
    "fi\n",
    "\n",
    "target_dir=$DIRECTORY/test_data\n",
    "if [ ! -d \"$target_dir\" ]; then\n",
    "    mkdir $target_dir\n",
    "fi\n",
    "\n",
    "\n",
    "cp -r ./container ./$DIRECTORY/\n",
    "cp run_docker.ipynb ./$DIRECTORY/run_docker.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can build a separate container for serving the model, or create a single container for both serving and hosting.  For the purpose of demonstrating how the serving process is different from the training, we will create a separate container here.\n",
    "\n",
    "Open up the container folder inside the MY_PROJECT folder, similiar to the training container folder and file structure, you will see the following folders and files\n",
    " - **code_base**:  this folder contains the files needed to run a flask server and inference code. The content in this folder will be copy to working folder when the Dockfile is built.  You will see the following files in the **code_base** directory\n",
    "\n",
    "     - **nginx.conf** contains configuration details for running nginx server. There is no need to change this file\n",
    "     - **wsgi.py** instantiates the flask server which is implemented by the predictor.py file\n",
    "     - **predictor.py** is the file that implements a flask server to do inferences. It's the file that you will modify to implement the scoring for your own algorithm. Specifically, you will need to make the following changes:\n",
    "        - import any packages as needed.  e.g. from sklearn.externals import joblib\n",
    "        - enter a file name for the **model_name** variable. This is the model file to be loaded.\n",
    "        - modify the **ScoringService->get_model()** function to load the model\n",
    "        - modify the **ScoringService->transformation()** to process the input data as needed. You might not need to modify this function if the existing code already meet your needs.\n",
    "     - **serve** implements the scoring service shell. You don't necessarily need to modify it for various algorithms. It starts nginx and gunicorn with the correct configurations and then simply waits until gunicorn exits\n",
    " - **Dockerfile**:  This is the Dockerfile used to build docker image.  Make changes as needed such as installing addtional packages.\n",
    " - **build_and_push.sh**:  This shell scripts builds the docker image and push to your AWS ECR. You will need to change the image name to something unique \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Build custom container\n",
    "\n",
    "Now you are ready to build the container. Open the **build_and_push.sh** file and change the name of the image.  Run **build_and_push.sh** in a terminal by typing **sh build_and_push.sh** to build a container and push to ECR.  Make sure you are in the right working directory below.\n",
    "\n",
    "`/home/ec2-user/SageMaker/SageMaker-Migration-Workshop/step-3/MY_PROJECT/container`\n",
    "\n",
    "You can list the docker images after it is built by typing the command below\n",
    "\n",
    "`docker images`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Local docker image testing\n",
    "\n",
    "First, we will download saved model from S3 bucket to local folder structure created for testing docker image locally.\n",
    "\n",
    "Enter a name for the modelpath for the model artifact in S3 before running the cell.  You can find the path of the model in the **SageMaker console->training jobs**. Select the training job and you can find the path to the model artifact under the **Output** section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-demo-dyping/timeseries-rf/models/timeseries-rf-2019-01-11-03-26-06-475/output/model.tar.gz to MY_PROJECT/container/opt/ml/model/model.tar.gz\n",
      "finalized_models_rf.sav\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# copy model from S3 to local directory for testing\n",
    "modelname=model.tar.gz\n",
    "modelpath=s3://sagemaker-demo-dyping/timeseries-rf/models/timeseries-rf-2019-01-11-03-26-06-475/output/model.tar.gz\n",
    "    \n",
    "aws s3 cp $modelpath $(pwd)/MY_PROJECT/container/opt/ml/model/$modelname\n",
    "\n",
    "cd $(pwd)/MY_PROJECT/container/opt/ml/model/\n",
    "tar -xvf $modelname\n",
    "rm $modelname\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Run docker image locally for testing.\n",
    "\n",
    "- Run the folllowing command in a terminal window. Make sure you provide a name for the serving docker image.  This starts the docker container locally on your notebook instance.\n",
    "\n",
    "\n",
    "`cd /home/ec2-user/SageMaker/SageMaker-Migration-Workshop/step-3`\n",
    "\n",
    "`image=<image name>`\n",
    "  \n",
    "`docker run -v $(pwd)/MY_PROJECT/container/opt/ml:/opt/ml -p 8080:8080 --rm ${image} serve`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Invoke locally running Docker container\n",
    "After the docker image is running in a the separate notebook, let's call the docker container.  \n",
    "\n",
    "1. copy the test file to the test_data directory\n",
    "2. Change the payload to the name of the test file and specify the content type (e.g. text/csv). \n",
    "\n",
    "You can status in the terminal window where the docker container is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 127.0.0.1...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 8080 (#0)\n",
      "> POST /invocations HTTP/1.1\n",
      "> Host: localhost:8080\n",
      "> User-Agent: curl/7.60.0\n",
      "> Accept: */*\n",
      "> Content-Type: text/csv\n",
      "> Content-Length: 10456\n",
      "> Expect: 100-continue\n",
      "> \n",
      "< HTTP/1.1 100 Continue\n",
      "} [10456 bytes data]\n",
      "* We are completely uploaded and fine\n",
      "100 10456    0     0  100 10456      0  51004 --:--:-- --:--:-- --:--:-- 50757< HTTP/1.1 200 OK\n",
      "< Server: nginx/1.14.0 (Ubuntu)\n",
      "< Date: Fri, 11 Jan 2019 04:04:45 GMT\n",
      "< Content-Type: text/csv; charset=utf-8\n",
      "< Content-Length: 20\n",
      "< Connection: keep-alive\n",
      "< \n",
      "{ [20 bytes data]\n",
      "100 10476  100    20  100 10456     86  45068 --:--:-- --:--:-- --:--:-- 44961\n",
      "* Connection #0 to host localhost left intact\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "cd MY_PROJECT/test_data/\n",
    "\n",
    "payload=test.csv\n",
    "content=text/csv\n",
    "\n",
    "curl --data-binary @${payload} -H \"Content-Type: ${content}\" -v http://localhost:8080/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create model and endpoint in SageMaker\n",
    "\n",
    "Now the image has been created and locally tested, we will now create a model in SageMaker and host it behind a API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session=sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Get the container image url\n",
    "\n",
    "First we need to create a name for the model.  Make sure the name is unique.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300165273893.dkr.ecr.us-west-2.amazonaws.com/timeseries-rf-serve:latest\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_tag = \"timeseries-rf-serve\"\n",
    "account = sagemaker_session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, image_tag)\n",
    "model_name = \"timeseries-model-1\"\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Create Model\n",
    "\n",
    "To create a model in SageMaker, we need 2 pieces of information\n",
    "\n",
    "1. image url for the serving container\n",
    "2. Path to the model artifact in S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-demo-dyping/timeseries-rf/models/timeseries-rf-2019-01-11-03-26-06-475/output/model.tar.gz\n",
      "arn:aws:sagemaker:us-west-2:300165273893:model/timeseries-model-1\n"
     ]
    }
   ],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "\n",
    "# name of the training job that create the model artifacts\n",
    "job_name =\"<name of training job>\"\n",
    "job_name=\"timeseries-rf-2019-01-11-03-26-06-475\"\n",
    "\n",
    "#you can use the training job name to look up the S3 location for the saved model artifact. \n",
    "#You can also find that information in the management console\n",
    "\n",
    "info = client.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "#Create the model\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Create Endpoint Configuration\n",
    "\n",
    "Next we need to create an endpoint configuration for hosting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeseries-rf-config\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-west-2:300165273893:endpoint-config/timeseries-rf-config\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = \"<name of endpoint config>\"\n",
    "endpoint_config_name = \"timeseries-rf-config\"\n",
    "print(endpoint_config_name)\n",
    "\n",
    "\n",
    "create_endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Create Endpoint\n",
    "\n",
    "Finally, we can now create the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeseries-rf-api-1\n",
      "arn:aws:sagemaker:us-west-2:300165273893:endpoint/timeseries-rf-api-1\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-west-2:300165273893:endpoint/timeseries-rf-api-1\n",
      "Status: InService\n",
      "CPU times: user 88.5 ms, sys: 9.4 ms, total: 97.9 ms\n",
      "Wall time: 6min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = \"<name of the endpoint>\"\n",
    "endpoint_name = \"timeseries-rf-api-1\"\n",
    "\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeseries-rf-api-1\n"
     ]
    }
   ],
   "source": [
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Test endpoint\n",
    "\n",
    "First load the test data as payload. Modify the code as needed depending on whether "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp_loc,pressforce-ch1-front-left,pressforce-ch2-rear-left,pressforce-ch3-rear-right,pressforce-ch4-front-right,isocrimp_cam1,isocrimp_cam3,box_breedter_cam1,box_breedter_cam3,gap_cam2,gap_cam4,draadcrimp_cam1,draadcrimp_cam3,lengtecontact_cam1,lengtecontact_cam3,iw_airpressure,iw_cabinettemperature,iw_presskraft_gesamt,iw_druck_oel_bar,iw_rollerballspressurenew80,iw_temp_oel_c,iw_releaselift1pressure400,iw_temp_motherboard,iw_temp_cpu,iw_achsgeber,iw_hubzahl,iw_druck_luft_bar,stroomverbruik,iw_winkelstellung,iw_presskraft_k1,iw_presskraft_k2,iw_presskraft_k3,iw_presskraft_k4,qw_oilpressurevalue,pressforce-ch1-front-left_rolling_mean,pressforce-ch1-front-left_rolling_std,pressforce-ch2-rear-left_rolling_mean,pressforce-ch2-rear-left_rolling_std,pressforce-ch3-rear-right_rolling_mean,pressforce-ch3-rear-right_rolling_std,pressforce-ch4-front-right_rolling_mean,pressforce-ch4-front-right_rolling_std,isocrimp_cam1_rolling_mean,isocrimp_cam1-right_rolling_std,isocrimp_cam3_rolling_mean,isocrimp_cam3-right_rolling_std,box_breedter_cam1-right_rolling_mean,box_breedter_cam1-right_rolling_std,box_breedter_cam3-right_rolling_mean,box_breedter_cam3-right_rolling_std,gap_cam2_rolling_mean,gap_cam2_rolling_std,gap_cam4_rolling_mean,gap_cam4_rolling_std,draadcrimp_cam1_rolling_mean,draadcrimp_cam1_rolling_std,draadcrimp_cam3_rolling_mean,draadcrimp_cam3_rolling_std,lengtecontact_cam1_rolling_mean,lengtecontact_cam1_rolling_std,lengtecontact_cam3_rolling_mean,lengtecontact_cam3_rolling_std\n",
      "2018-10-06 03:52:30,11.519198664440735,9.176961602671119,13.123539232053425,10.195325542570954,2.885,2.881,1.607,1.616,0.375,0.375,1.753,1.744,15.126,15.066,5612.0,253.0,240.6476,2.825,0.0,32.0,0.0,33.0,43.0,0.0,652.0,5.615,0.0,5.625,57.15221800000001,60.41061,62.35896999999999,59.064137,2.82,11.094411982934464,0.2432334503244957,9.16809033574477,0.2343858167778391,13.361969022444795,0.1826932358866644,10.371586904099411,0.1442097998943708,2.8830416666666685,0.0029871474914608532,2.88110416666674,0.0010081060719075846,1.6079347222221805,0.00041796686851459464,1.6187138888889099,0.001055599942689103,0.3721097222222262,0.0017729128512805675,0.3734500000000141,0.0012880422837491705,1.7525263888888785,0.001052916503679836,1.7447208333333433,0.0004998432901698667,15.125372222222314,0.0008084205550640557,15.064877777777722,0.0010990274546019928\n",
      "2018-10-18 08:05:20,11.328881469115192,8.91652754590985,13.088480801335555,10.407345575959932,2.92,2.9685,1.609,1.6165,0.379,0.375,1.7495,1.743,15.1145,15.058,5620.0,245.0,239.17557,2.829,0.0,32.8,0.0,32.0,41.0,0.0,652.0,5.6160000000000005,0.0,194.50195,60.0777,60.206215,61.72433,58.386314,2.81,11.133161751066568,0.2355714682370829,9.145946948618072,0.25814058058115164,13.321675013912033,0.18847813863268129,10.394509367464279,0.1447931366177463,2.9153958333333114,0.002466682582999276,2.9712888888888864,0.0017531948949387867,1.6092236111111438,0.0004311974202352772,1.6189750000000132,0.001290391963118608,0.3789861111111064,0.0013262199990591106,0.3750416666666826,0.0011519330973042312,1.747766666666669,0.0008557522882414769,1.7435125000000382,0.000526971031381228,15.114820833333154,0.0008975263913343109,15.060912500000086,0.0012511763280007345\n",
      "2018-09-03 19:09:50,11.07679465776294,8.667779632721203,13.101836393989982,10.540901502504171,2.874,2.877,1.597,1.608,0.37,0.345,1.753,1.744,15.121,15.077,5615.0,249.0,236.49619,0.0,0.0,31.8,0.0,33.0,41.0,0.0,0.0,5.6160000000000005,0.0,8.261719,57.45647,58.230377,61.277737,59.5316,0.0,11.306534038211751,0.3057558561488913,8.645302355778169,0.5855398061704735,12.859093860137394,0.5394834091835434,10.375445186421887,0.2074912861089411,2.8758972222221963,0.0014484620815322178,2.880136111111136,0.0024439856003212425,1.5976361111110782,0.0004817868191247693,1.6080194444443916,0.0001739584108667774,0.3681249999999915,0.0014903356261484315,0.3380722222222246,0.0053313918239582744,1.7529888888889231,0.00010496790263885495,1.74462777777779,0.0004897905362612259,15.121005555555673,7.443171405296459e-05,15.07573888888891,0.0009666522582993484\n",
      "2018-08-29 08:25:40,11.54424040066778,8.973288814691152,13.040066777963276,10.524207011686146,2.881,2.874,1.599,1.624,0.371,0.348,1.7480000000000002,1.742,15.124,15.084,5631.0,253.0,239.80974,2.804,0.0,32.6,0.0,33.0,42.0,0.0,651.0,5.6320000000000014,0.0,270.0,56.894775,60.932957,61.442272,58.175953,2.79,11.374633648673635,0.22604286215109035,9.085709979595627,0.2554384528685903,13.274749582637716,0.17520694369799936,10.500447505101086,0.128049908561105,2.88113333333333,0.003357567430877875,2.8746430555555675,0.0022253807153738625,1.599311111111134,0.0008314091061617108,1.6234972222222228,0.0017512408829577436,0.3704444444444439,0.0016398492430949089,0.3463347222222217,0.001453950503791922,1.7504944444444361,0.0014749428853312765,1.7418472222222052,0.0007219156313825569,15.123949999999947,0.0014382363077969536,15.0832736111111,0.001191660092458941\n",
      "2018-09-03 13:44:20,11.661101836393993,8.849749582637731,13.193656093489148,10.332220367278797,2.879,2.883,1.597,1.605,0.371,0.333,1.753,1.744,15.122,15.079,5620.0,261.0,233.69002000000003,2.801,0.0,32.2,0.0,34.0,43.0,0.0,652.0,5.624,0.0,70.13672,56.00543,61.137356,60.54908,57.21765,2.78,11.6102369690224,0.2719446440378405,9.075955295863476,0.3850728240230345,12.617649786681481,0.4045628601867302,10.2015396030421,0.2200423076319684,2.8796194444444425,0.002392166818164705,2.8784138888888844,0.002639601216828733,1.5974430555555352,0.0007493407294803199,1.6072472222222167,0.0019431310503777726,0.3679027777777757,0.0021552534910456926,0.3352930555555554,0.002645399980228065,1.7536444444444508,0.0010308458393531452,1.7430638888889127,0.0007380063401323117,15.122148611111125,0.0009969302541863426,15.077191666666794,0.0019693154500930524\n",
      "2018-09-06 00:00:40,11.56761268781302,8.731218697829716,12.091819699499164,9.796327212020033,2.872,2.865,1.597,1.606,0.373,0.34600000000000003,1.758,1.742,15.123,15.079,5645.0,228.0,234.86829,0.0,0.0,29.1,0.0,31.0,38.0,0.0,0.0,5.647,0.0,30.498047,55.70118000000001,61.160065,61.72433,56.282722,0.0,11.567612687813272,8.187775597517967e-08,8.731218697829716,1.447752273834258e-07,12.091819699498913,2.3013064183027697e-07,9.796327212020056,0.0,2.872000000000066,2.6501017351850507e-08,2.8650000000000118,5.205938862546682e-08,1.5969999999999818,0.0,1.6059999999999932,0.0,0.3729999999999865,0.0,0.3460000000000045,1.0048377064798915e-08,1.7580000000000302,0.0,1.7419999999999605,0.0,15.122999999999616,2.621525296624736e-08,15.078999999999775,1.2867352663502815e-08\n",
      "2018-09-06 09:19:00,11.464106844741234,9.098497495826377,12.709515859766276,9.769616026711184,2.873,2.87,1.599,1.609,0.366,0.343,1.7619999999999998,1.745,15.12,15.074000000000002,5626.0,248.0,224.35655,2.81,0.0,31.9,0.0,32.0,41.0,0.0,652.0,5.629,0.0,342.0703,54.811832,58.457485,58.034035,54.763462,2.81,11.567056204786002,0.007459761655273338,8.7327258393619,0.0214257364415232,12.095223520682369,0.045604937914981485,9.796684288629221,0.008306937401998045,2.872005555555621,7.443172153207398e-05,2.865027777777789,0.00037215858778606384,1.5970138888888707,0.00018978477435026132,1.6060138888888822,0.00018978477414858803,0.37295555555554216,0.0006001134732085101,0.34598055555556,0.0002631705597592804,1.758022222222252,0.00029772686726619365,1.7420166666666277,0.00022329515040493862,15.122986111110725,0.00018978477622177015,15.078974999999776,0.00033701541113947747\n",
      "2018-09-12 06:04:10,11.585976627712855,9.018363939899832,13.033388981636062,10.517529215358932,2.88,2.885,1.602,1.624,0.363,0.35700000000000004,1.756,1.745,15.119000000000002,15.082,5626.0,253.0,237.57263,2.85,0.0,32.3,0.0,33.0,41.0,0.0,652.0,5.622999999999998,0.0,120.32226599999998,59.70324,61.091934,61.5833,57.544876,2.85,11.423845297718296,0.2227554152442768,9.169082730476717,0.2483064578245702,13.13050454461133,0.17841497272598966,10.385332034872926,0.1442765081939295,2.8782416666666584,0.0025817956002796003,2.885594444444437,0.002040528692890604,1.6018388888888706,0.00046956257677769735,1.6238902777778013,0.0007610211054947276,0.359787499999999,0.0024506231088334885,0.3558750000000051,0.002881781695110084,1.7552374999999822,0.0021776554245153293,1.7450388888888912,0.0010151437670688854,15.121070833333304,0.0011325074482254054,15.081231944444625,0.0009001433483197039\n",
      "2018-08-29 08:45:20,11.175292153589316,9.195325542570954,13.235392320534224,10.35058430717863,2.8805,2.8760000000000003,1.5985,1.6215000000000002,0.373,0.34600000000000003,1.7494999999999998,1.743,15.124,15.0855,5629.0,254.0,238.704,2.804,0.0,32.5,0.0,33.0,42.0,0.0,652.0,5.631,0.0,116.98242,59.04793000000001,59.97910699999999,61.48928000000001,58.386314,2.8,11.386231682433591,0.2262598070787684,9.058532739751435,0.2517392508883116,13.282693377851968,0.17713073047817166,10.511904099424957,0.13078845500751532,2.881027777777778,0.003366524629963349,2.874350000000017,0.002221319841539661,1.5995333333333512,0.0010370571176014926,1.6231513888888907,0.0018663560683009168,0.3705791666666661,0.001745263187405566,0.3465833333333331,0.0015090257699518833,1.7502708333333292,0.0015363232072679017,1.741997222222212,0.0008344885214838977,15.124201388888848,0.0013940275567707278,15.083613888888864,0.0012403730182594206\n",
      "2018-09-04 16:26:50,11.470784641068445,8.843071786310517,12.92320534223706,10.54424040066778,2.873,2.875,1.598,1.6065,0.3685,0.339,1.754,1.745,15.1245,15.0755,5626.0,258.0,239.41238,2.858,0.0,32.1,0.0,34.0,43.0,0.0,651.0,5.62,0.0,176.83594,57.503277,62.45458000000001,61.442272,57.124157,2.85,11.41093952884439,0.23467521099489444,9.032827861250224,0.24566210834445104,13.006844741235385,0.17235535921774708,10.496447783342596,0.13976314811723692,2.875068055555549,0.0015532180977607642,2.8757999999999906,0.0011984205020696553,1.5971944444444246,0.0007019449479155682,1.6067930555555323,0.0008408654495175609,0.3691611111111076,0.001831826003128195,0.3426180555555555,0.0016247842272940562,1.7533388888889008,0.0007963278456371389,1.7441694444444673,0.000757807806102014,15.12507361111114,0.0009438251248835428,15.077123611111258,0.0014154433790619393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_name = 'MY_PROJECT/test_data/test.csv' #customize to your test file\n",
    "\n",
    "#input_df = pd.read_csv(file_name, index_col=None, header=None)\n",
    "\n",
    "input_df = pd.read_csv(file_name)\n",
    "\n",
    "input_df=input_df.set_index('timestamp_loc')\n",
    "\n",
    "#payload = input_df.to_csv(index=None, header=None)\n",
    "payload = input_df.to_csv()\n",
    "\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next invoke the endpoint with payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtime_client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='text/csv', \n",
    "                                   Body=payload)\n",
    "result = response['Body'].read()\n",
    "result = result.decode(\"utf-8\")\n",
    "result = result.split(',')\n",
    "#label = payload.strip(' ').split()[0]\n",
    "#print ('Input: ',label,'\\nPrediction: ', result[0])\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: Batch-Transform-2018-12-21-01-09-49-690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................!\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "model_name = 'credit-model-2018-12-20-17-46-53-438-model'\n",
    "input_location = 's3://sagemaker-demo-dyping/sk-lab/batch/test1.csv'\n",
    "output_location = 's3://sagemaker-demo-dyping/sk-lab/batch/output/'\n",
    "\n",
    "transformer =sagemaker.transformer.Transformer(\n",
    "    base_transform_job_name='Batch-Transform',\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    output_path=output_location\n",
    "    )\n",
    "# To start a transform job:\n",
    "transformer.transform(input_location, content_type='text/csv', split_type='Line')\n",
    "# Then wait until transform job is completed\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
